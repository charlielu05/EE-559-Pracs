{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dlc_practical_prologue import load_data\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the two functions <br>\n",
    "def sigma(x) <br>\n",
    "def dsigma(x) <br> \n",
    "that take as input a ﬂoat tensor and returns a tensor of same size, obtained by applying component-wise respectively tanh, and the ﬁrst derivative of tanh. <br>\n",
    "Hint: The functions should have no python loop, and use in particular torch.tanh , torch.exp , torch.mul , and torch.pow . My versions are 34 and 62 character long. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return x.tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigma(x):\n",
    "    return 1 - torch.pow(sigma(x), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       " 0.4200\n",
       "[torch.cuda.FloatTensor of size 10 (GPU 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsigma(test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Loss\n",
    "Write the two functions <br>\n",
    "\n",
    "def loss(v, t) <br>\n",
    "def dloss(v, t) <br>\n",
    "\n",
    "that take as input two ﬂoat tensors of same dimensions with v the predicted tensor and t the target one, and return respectively abs(v-t)^2, and a tensor of same size equal to the gradient of that quantity as a function of v. <br>\n",
    "\n",
    "Hint: The functions should have no python loop, and use in particular torch.sum , torch.pow . My versions are 48 and 40 character long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.ones(10).fill_(10)\n",
    "t = torch.ones(10).fill_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(v, t):\n",
    "    return torch.pow((v-t), 2).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss(v, t):\n",
    "    return 2 * (v - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Forward/Back Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(w1, b1, w2, b2, x):\n",
    "    x0 = x\n",
    "    s1 = torch.mv(w1.t(), x0) + b1\n",
    "    x1 = sigma(s1)\n",
    "    s2 = torch.mv(w2.t(), x1) + b2\n",
    "    x2 = sigma(s2)\n",
    "\n",
    "    return x0, s1, x1, s2, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    x0 = x\n",
    "    dl_dx2 = dloss(x2, t)\n",
    "    dl_ds2 = dsigma(s2) * dl_dx2\n",
    "    dl_dx1 = w2.t().mv(dl_ds2)\n",
    "    dl_ds1 = dsigma(s1) * dl_dx1\n",
    "\n",
    "    dl_dw2.add_(dl_ds2.view(-1, 1).mm(x1.view(1, -1)))\n",
    "    dl_db2.add_(dl_ds2)\n",
    "    dl_dw1.add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_db1.add_(dl_ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(cifar = None, one_hot_labels = True, normalize = True, flatten = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply target label by 0.9 (fall within value of tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_target * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_input * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the w1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Tensor(784, 50).normal_(0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = Tensor(50, 10).normal_(0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = Tensor(50).normal_(0, 1e-6)\n",
    "b2 = Tensor(10).normal_(0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dw2 = Tensor(w2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dw1 = Tensor(w1.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_b1 = Tensor(b1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_b2 = Tensor(b2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1.00000e-06 *\n",
       " -0.6545\n",
       " -0.7528\n",
       " -1.1291\n",
       " -0.2537\n",
       " -1.2630\n",
       " -0.1830\n",
       "  0.3645\n",
       " -0.3536\n",
       " -0.0948\n",
       " -2.1960\n",
       "[torch.cuda.FloatTensor of size 10 (GPU 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index location of the maximum prediction value\n",
    "x2.max(0)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " 1.00000e-07 *\n",
       "   3.6450\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  6\n",
       " [torch.cuda.LongTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " 1.00000e-07 *\n",
       "   3.6450\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  6\n",
       " [torch.cuda.LongTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.9000\n",
       "-0.9000\n",
       "-0.9000\n",
       "-0.9000\n",
       "-0.9000\n",
       " 0.9000\n",
       "-0.9000\n",
       "-0.9000\n",
       "-0.9000\n",
       "-0.9000\n",
       "[torch.cuda.FloatTensor of size 10 (GPU 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8999999761581421"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the row index and column index from the prediction should be larger than 0\n",
    "train_target[0,6] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for 1000 epochs \n",
    "for k in range(0, 1000):\n",
    "    \n",
    "    acc_loss = 0\n",
    "    nb_train_errors = 0\n",
    "    \n",
    "    dl_dw1.zero()\n",
    "    dl_db1.zero()\n",
    "    dl_dw2.zero()\n",
    "    dl_db2.zero()\n",
    "    \n",
    "    for n in range(0, nb_train_samples):\n",
    "        x0, s1, x1, s2 , x2 = forward_pass(w1, b1, w2, b2, train_input[n])\n",
    "        \n",
    "        pred = x2.max(0)[1][0] # the column location of maximum prediction\n",
    "        if train_target[n, pred] < 0 : nb_train_errors += 1 # train_target[n, pred] should return positive integer if predicted correctly\n",
    "        acc_loss = acc_loss + loss (x2, train_target[n])\n",
    "        \n",
    "        backward_pass(w1, b1, w2, b2, train_target[n], x0, s1, x1, s2, x2, dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
    "        # the backward pass stage will set dl_dw1 ~ dl_db2 \n",
    "        \n",
    "        w1 = w1 - eta * dl_dw1\n",
    "        b1 = b1 - eta * dl_db1\n",
    "        w2 = w2 - eta * dl_dw2\n",
    "        b2 = b2 - eta * dl_db2\n",
    "        \n",
    "        nb_test_errors = 0 \n",
    "        \n",
    "        \n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
